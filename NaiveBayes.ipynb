{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reviewing the news dataset\n",
    "* 정치, 종교, 스포츠, 과학과 같은 20개의 다른 주제의 약 19,000개 뉴스 메시지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "categories = ['alt.atheism', 'soc.religion.christian','comp.graphics', 'sci.med']\n",
    "news = fetch_20newsgroups(subset='all', categories=categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = news.data\n",
    "target = news.target\n",
    "target_names = news.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TARGET NAMES ===\n",
      "['alt.atheism', 'comp.graphics', 'sci.med', 'soc.religion.christian']\n"
     ]
    }
   ],
   "source": [
    "print( \"=== TARGET NAMES ===\")\n",
    "print( target_names )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Data ===\n",
      "From: geb@cs.pitt.edu (Gordon Banks)\n",
      "Subject: Re: \"CAN'T BREATHE\"\n",
      "Article-I.D.: pitt.19440\n",
      "Reply-To: geb@cs.pitt.edu (Gordon Banks)\n",
      "Organization: Univ. of Pittsburgh Computer Science\n",
      "Lines: 23\n",
      "\n",
      "In article <1993Mar29.204003.26952@tijc02.uucp> pjs269@tijc02.uucp (Paul Schmidt) writes:\n",
      ">I think it is important to verify all procedures with proper studies to\n",
      ">show their worthiness and risk.  I just read an interesting tidbit that \n",
      ">80% of the medical treatments are unproven and not based on scientific \n",
      ">fact.  For example, many treatments of prostate cancer are unproven and\n",
      ">the treatment may be more dangerous than the disease (according to the\n",
      ">article I read.)\n",
      "\n",
      "Where did you read this?  I don't think this is true.  I think most\n",
      "medical treatments are based on science, although it is difficult\n",
      "to prove anything with certitude.  It is true that there are some\n",
      "things that have just been found \"to work\", but we have no good\n",
      "explanation for why.  But almost everything does have a scientific\n",
      "rationale.  The most common treatment for prostate cancer is\n",
      "probably hormone therapy.  It has been \"proven\" to work.  So have\n",
      "radiation and chemotherapy.  What treatments did the article say\n",
      "are not proven?  \n",
      "\n",
      "-- \n",
      "----------------------------------------------------------------------------\n",
      "Gordon Banks  N3JXP      | \"Skepticism is the chastity of the intellect, and\n",
      "geb@cadre.dsl.pitt.edu   |  it is shameful to surrender it too soon.\" \n",
      "----------------------------------------------------------------------------\n",
      "\n",
      "=== Target ===\n",
      "2\n",
      "=== Target Name ===\n",
      "sci.med\n"
     ]
    }
   ],
   "source": [
    "print( \"=== Data ===\")\n",
    "print( data[0] )\n",
    "print( \"=== Target ===\")\n",
    "print( target[0] )\n",
    "print( \"=== Target Name ===\")\n",
    "print( target_names[target[0]] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 문서 전처리\n",
    "* 기계학습 모델은 수치 데이터 상에서 작동\n",
    "* 문서(document) 역시 숫자로 구성된 자질 벡터(feature vector)를 추출하는 과정이 필요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'this': 9, 'is': 3, 'the': 7, 'first': 2, 'document': 1, 'second': 6, 'and': 0, 'third': 8, 'one': 5, 'last': 4}\n",
      "[0 1 0 1 0 0 2 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "corpus = [\n",
    "    'This is the first document.',\n",
    "    'This is the second second document.',\n",
    "    'And the third one.',\n",
    "    'Is this the first document?',\n",
    "    'The last document?',    \n",
    "]\n",
    "vect = CountVectorizer()\n",
    "corpus_feature = vect.fit_transform(corpus).toarray()\n",
    "\n",
    "print(vect.vocabulary_)\n",
    "#['and' 'document' 'first' 'is' 'last' 'one' 'second' 'the' 'third' 'this' ]\n",
    "print(corpus_feature[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3759, 47319)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer()\n",
    "X = count_vect.fit_transform(data).toarray()\n",
    "\n",
    "print(np.shape(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3007 752\n",
      "3007 752\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, target, test_size=0.2)\n",
    "\n",
    "print(len(X_train), len(X_test))\n",
    "print(len(y_train), len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        precision    recall  f1-score   support\n",
      "\n",
      "           alt.atheism       0.99      0.98      0.98       146\n",
      "         comp.graphics       0.96      0.98      0.97       192\n",
      "               sci.med       0.99      0.97      0.98       212\n",
      "soc.religion.christian       0.98      0.99      0.98       202\n",
      "\n",
      "           avg / total       0.98      0.98      0.98       752\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "from sklearn import metrics\n",
    "print(metrics.classification_report(y_test, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.974458748432\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import cross_val_score\n",
    "# warning: sklearn version 0.20 => from sklearn.model_selection import cross_val_score\n",
    "\n",
    "accuracys = cross_val_score(MultinomialNB(), X, target, cv=10, scoring='accuracy')\n",
    "print(accuracys.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "     건강과 의학       0.00      0.00      0.00         3\n",
      "         경제       0.46      0.96      0.62        25\n",
      "         과학       0.00      0.00      0.00         2\n",
      "         교육       1.00      0.33      0.50         3\n",
      "     문화와 종교       0.83      0.42      0.56        12\n",
      "         사회       0.73      0.85      0.79        13\n",
      "         산업       0.33      0.09      0.14        22\n",
      "\n",
      "avg / total       0.52      0.54      0.46        80\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     건강과 의학       0.00      0.00      0.00         1\n",
      "         경제       0.58      0.72      0.64        25\n",
      "         과학       0.00      0.00      0.00         2\n",
      "         교육       1.00      0.20      0.33         5\n",
      "     문화와 종교       0.80      0.75      0.77        16\n",
      "         사회       0.64      0.64      0.64        14\n",
      "         산업       0.37      0.41      0.39        17\n",
      "\n",
      "avg / total       0.59      0.59      0.57        80\n",
      "\n",
      "0.482042055712\n",
      "0.520236644079\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "\n",
    "\n",
    "lines=[]\n",
    "target_names=[]\n",
    "target=[]\n",
    "length=0\n",
    "\n",
    "def unique(seq):\n",
    "    seen = set()\n",
    "    seen_add = seen.add\n",
    "    return [x for x in seq if not (x in seen or seen_add(x))]\n",
    "\n",
    "def bigrams(input_list):\n",
    "    return [list(a) for a in zip(input_list, input_list[1:])]\n",
    "\n",
    "regex=['NNG','NNP','NNB','NP','NR','VV','VX','VCP','VCN','MAG','MAJ']\n",
    "\n",
    "with open(\"C:/news.txt\") as f:\n",
    "    for line in f:\n",
    "        if(line.startswith(';')):\n",
    "            target_names.append(line[1:-1])\n",
    "        lines.append(line.replace(\" \",\"\").replace(\"\\t\",\"\").split('+'))\n",
    "        length+=1\n",
    "        \n",
    "target_name=unique(target_names)\n",
    "\n",
    "enc = LabelEncoder()\n",
    "label_encoder = enc.fit(target_names)\n",
    "target = label_encoder.transform(target_names)\n",
    "        \n",
    "resultlist = []   \n",
    "\n",
    "for j in range(length):        \n",
    "    for i in range(len(lines[j])):\n",
    "          for s in range(len(regex)):        \n",
    "                if regex[s] in lines[j][i]:     \n",
    "                    resultlist.append(lines[j][i])\n",
    "                    break\n",
    "    if(j>=1 and \" \".join(lines[j]).startswith(';')): #;으로 시작하는 경우               \n",
    "        resultlist.append('\\c')   #data구분기호 삽입\n",
    "        \n",
    "data=(\" \".join(resultlist).split('\\c'))   #구분기호 기준으로 split\n",
    "data2=list(bigrams(resultlist))\n",
    "\n",
    "for i in range(len(data2)):\n",
    "    (data2[i])=(\"/\".join(data2[i]))\n",
    "    \n",
    "data2=(\" \".join(data2).split('\\c'))  #구분기호 기준으로 split\n",
    "\n",
    "for i in range(1,400):    #구분기호가 두 개씩 들어가서 중간에 공백리스트가 하나씩 들어간다.\n",
    "    data2[i]=data2[i*2]   #이를 해결하기 위함.\n",
    "\n",
    "data2=data2[0:400]\n",
    "\n",
    "\"\"\"\n",
    "data 출력\n",
    "1번\n",
    "print (data)\n",
    "\n",
    "2번\n",
    "print (data2)\n",
    "\"\"\"\n",
    "\n",
    "#CountVectorizer \n",
    "count_vect = CountVectorizer()\n",
    "X1= count_vect.fit_transform(data).toarray()\n",
    "count_vect = CountVectorizer()\n",
    "X2 = count_vect.fit_transform(data2).toarray()\n",
    "\n",
    "#split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X1, target, test_size=0.2)\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X2, target, test_size=0.2)\n",
    "\n",
    "#Model Learning\n",
    "clf = MultinomialNB().fit(X_train, y_train)\n",
    "clf2 = MultinomialNB().fit(X2_train, y2_train)\n",
    "\n",
    "#Evaluation 3번\n",
    "y_pred = clf.predict(X_test)\n",
    "print(metrics.classification_report(y_test, y_pred, target_names=target_name))\n",
    "\n",
    "y2_pred = clf2.predict(X2_test)\n",
    "print(metrics.classification_report(y2_test, y2_pred, target_names=target_name))\n",
    "\n",
    "accuracys = cross_val_score(MultinomialNB(), X1, target, cv=5, scoring='accuracy')\n",
    "print(accuracys.mean())\n",
    "accuracys2 = cross_val_score(MultinomialNB(), X2, target, cv=5, scoring='accuracy')\n",
    "print(accuracys2.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
